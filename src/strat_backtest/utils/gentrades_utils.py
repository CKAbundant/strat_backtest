"""Utility functions used in 'GenTrades' class."""

from datetime import datetime
from decimal import Decimal
from pathlib import Path
from typing import Any

import pandas as pd

from strat_backtest.utils.constants import ExitMethod
from strat_backtest.utils.dataframe_utils import set_as_index, set_naive_tz
from strat_backtest.utils.pos_utils import correct_datatype


def get_module_paths(main_pkg: str = "strat_backtest") -> dict[str, str]:
    """Convert file path to package path that can be used as input to importlib.

    Args:
        script_path (str):
            Relative path to python script containig required module.
        main_pkg (str):
            Name of main package to generate module path
            (Default: "strat_backtest").

    Returns:
        module_info (dict[str, str]):
            Dictionary mapping each concrete class to module path.
    """

    # Get main package directory path
    main_pkg_path = Path(__file__).parents[1]

    # Get list of folder paths containin concrete implementation of 'EntryStruct',
    # 'ExitStruct', 'StopLoss' and 'TrailProfit' abstract class.
    folder_paths = [
        rel_path
        for rel_path in main_pkg_path.iterdir()
        if rel_path.is_dir() and rel_path.name not in {"base", "utils", "__pycache__"}
    ]

    module_info = {}

    # Iterate through contents of each folder path
    for folder in folder_paths:
        # Get all python scripts inside folder
        for file_path in folder.glob("*.py"):
            file_name = file_path.stem
            folder_name = folder.stem

            # Ignore __init__.py
            if file_name == "__init__":
                continue

            # Get name of concrete class
            class_name = "".join(
                part.upper() if part in {"fifo", "lifo"} else part.title()
                for part in file_name.split("_")
            )

            module_info[class_name] = f"{main_pkg}.{folder_name}.{file_name}"

    return module_info


def append_info(
    df_signals: pd.DataFrame,
    info_list: list[dict[str, str | datetime | Decimal]] | None = None,
) -> pd.DataFrame:
    """Convert 'info_list' (i.e. stop loss or trailing profit info) to DataFrame
    and append to 'df_signals'."""

    if len(info_list) == 0:
        return df_signals

    # Convert 'info_list' to DataFrame
    df_info = pd.DataFrame(info_list)

    df_list = []

    # Set all date-related columns to naive time zone
    # Set 'date' as index to faciliate join
    for data in [df_signals, df_info]:
        data = set_naive_tz(data, reset_time=True)
        data = set_as_index(data, "date")
        df_list.append(data)

    # Join DataFrame via 'date' index
    df_signals, df_info = df_list
    df = df_signals.join(df_info)

    # Convert 'date' index to column
    df = df.reset_index()

    return df


def gen_mapping(record: tuple[Any], req_cols: list[str]) -> dict[str, Any]:
    """Generate mapping for record generated by 'itertuples' method given
    list of required columns."""

    # Record include row index and required fields
    fields = ["idx", *req_cols]

    # Create dictionary by matching column names to respective fields
    record = dict(zip(fields, record))

    # Ensure numeric type are set to Decimal and date type are set to datetime
    record = correct_datatype(record)

    return record


def validate_req_cols(
    df: pd.DataFrame, req_cols: list[str], exit_struct: ExitMethod
) -> pd.DataFrame:
    """Ensure all columns in 'self.req_cols' are present in DataFrame; and return
    filtered DataFrame based on 'self.req_cols' columns.

    Args:
        df (pd.DataFrame): DataFrame containing OHLCV and other relevant info.
        req_cols (list[str]): list of required columns.
        exit_struct (ExitMethod): Exit strategy e.g. 'FixedExit', etc.

    Returns:
        (pd.DataFrame): Validated DataFrame with required columns.
    """

    # 'profit' and 'stop' columns are required if exit_struct is 'FixedExit'
    if exit_struct == "FixedExit":
        req_cols.extend(["stop"])

    not_available = [col for col in req_cols if col not in df.columns]

    if not_available:
        raise ValueError(f"{not_available} required columns are missing!")

    return df.loc[:, req_cols]
